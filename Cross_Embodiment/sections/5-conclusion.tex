\section{Conclusion}
We present \our, a scalable cross-humanoid whole-body controller and training framework that enables zero-shot embodiment generalization. Extensive simulation and real-world experiments show that generalist policy transfers robustly across diverse humanoid robots, despite substantial differences in degrees of freedom, dynamics, and kinematic topologies. The learned policy further supports precise and stable control for long-horizon whole-body tasks.

While effective, \our relies on a unified command interface in which all robots are driven by control signals with shared semantics. This simplifies the learning process but limits applicability to more expressive control settings.
For example, motion tracking requires embodiment-specific retargeting, leading to a mismatch between motion representation and robot morphology.
Extending cross‑embodiment learning to support expressive, morphology‑aware control remains an important direction for future work.
